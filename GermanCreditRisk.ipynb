{"cells":[{"cell_type":"markdown","source":["###Anomaly Detection : German Credit Risk\n\n1. Import all libarires."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import PCA\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\n\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.clustering import GaussianMixture\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\nimport numpy as np\n\nfrom matplotlib import  pyplot as plt\n\nimport matplotlib as mpl"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["### Load german credit data"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\nschema = StructType([\n\nStructField(\"creditability\", IntegerType(), True),\n\nStructField(\"balance\", IntegerType(), True),\n\nStructField(\"duration\", IntegerType(), True),\n\nStructField(\"history\", IntegerType(), True),\n\nStructField(\"purpose\", IntegerType(), True),\n\nStructField(\"amount\", IntegerType(), True),\n\nStructField(\"savings\", IntegerType(), True),\n\nStructField(\"employment\", IntegerType(), True),\n\nStructField(\"instPercent\", IntegerType(), True),\n\nStructField(\"sexMarried\", IntegerType(), True),\n\nStructField(\"guarantors\", IntegerType(), True),\n\nStructField(\"residenceDuration\", IntegerType(), True),\n\nStructField(\"assets\", IntegerType(), True),\n\nStructField(\"age\", IntegerType(), True),\n\nStructField(\"concCredit\", IntegerType(), True),\n\nStructField(\"apartment\", IntegerType(), True),\n\nStructField(\"credits\", IntegerType(), True),\n\nStructField(\"occupation\", IntegerType(), True),\n\nStructField(\"dependents\", IntegerType(), True),\n\nStructField(\"hasPhone\", IntegerType(), True),\n\nStructField(\"foreign\", IntegerType(), True)\n\n])\nGermanDF = sqlContext.read.format('com.databricks.spark.csv').options(header='false', inferSchema='true').load('/FileStore/tables/uukouu8x1474353982100/German_cleanData.csv',schema=schema)\n\n\n\n\n\n\n#GermanDF = sqlContext.read.format('com.databricks.spark.csv').options( #inferSchema='true').load('/FileStore/tables/uukouu8x1474353982100/German_cleanData.csv')\n\n\nGermanDF.show(4)\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["Apply basic statistics here to process data"],"metadata":{}},{"cell_type":"code","source":["# register the Customers frame as table\nGermanDF.registerTempTable('credit')\n# query the credability table to check average balance amount,average loan and average duration for\n\n# each class of customer i.e. 1 and 0\n\nresults =  sqlContext.sql(\"SELECT creditability, avg(balance) as avgbalance, avg(amount) as avgamt,avg(duration) as avgdur  FROM credit GROUP BY creditability\")\n# check the result of the query\n\nresults.show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["Basic_stat = GermanDF.describe('creditability','balance','duration','history','purpose')\nGermanDF.describe('creditability','balance','duration','history','purpose').show()\n#GermanDF.describe(\"amount\",\"savings\", \"employment\", \"instPercent\",\"sexMarried\").show()\n#GermanDF.describe(\"guarantors\",\"residenceDuration\", \"assets\", \"age\", \"concCredit\").show()\n#GermanDF.describe(\"apartment\",\"credits\", \"occupation\", \"dependents\", \"hasPhone\").show()\n#GermanDF.describe(\"foreign\").show()\n\ndisplay(Basic_stat)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["###Pre-process the data"],"metadata":{}},{"cell_type":"code","source":["GermanDF = GermanDF.withColumnRenamed(\"foreign\",\"label\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### Transform 20 features into MLlib vectors"],"metadata":{}},{"cell_type":"code","source":["#assembler = VectorAssembler(\n#    inputCols=['C%d' % i for i in range(20)],\n#    outputCol=\"features\") \n\n\nassembler = VectorAssembler(inputCols=[\"creditability\",\"balance\",\"duration\",\"history\",\"purpose\",\"amount\",\"savings\",\"employment\",\"instPercent\",\"sexMarried\",\"guarantors\",\"residenceDuration\",\"assets\",\"age\",\"concCredit\",\"apartment\",\"credits\",\"occupation\",\"dependents\",\"hasPhone\"],\n    outputCol=\"features\") \n\noutput = assembler.transform(GermanDF)\n\noutput.show(4)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### StandardScaler : is feature Transformer\n###Scale features to have zero mean and one unit standard deviation\n\nWhether to standardize the data prior to a PCA on the covariance matrix depends on the measurement scales of the original features. Since PCA yields a feature subspace that maximizes the variance along the axes, it makes sense to standardize the data, especially, if it was measured on different scales."],"metadata":{}},{"cell_type":"code","source":["\nstandardizer = StandardScaler(withMean=True, withStd=True,\n                              inputCol='features',\n                              outputCol='std_features')\nmodel = standardizer.fit(output)\noutput = model.transform(output)\n\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["output.show(4)\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["###Convert label to numeric index\n\n######StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the #####most frequent label gets index 0. If the input column is numeric, we cast it to string and index the string values. When downstream pipeline components #####such as Estimator or Transformer make use of this string-indexed label, you must set the input column of the component to this string-indexed column #####name. In many cases, you can set the input column with setInputCol."],"metadata":{}},{"cell_type":"code","source":["indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_idx\")\nindexed = indexer.fit(output).transform(output)\n\nprint indexed.show(4)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["###Extract only columns of interest"],"metadata":{}},{"cell_type":"code","source":["german = indexed.select(['std_features', 'label', 'label_idx'])\n\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["german.show(n=3, truncate=False) "],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["###Data conversion\n\n######We will first fit a Gaussian Mixture Model with 2 components to the first 2 principal components of the data as an example of unsupervised learning. #####The GaussianMixture model requires an RDD of vectors, not a DataFrame. Note that pyspark converts numpy arrays to Spark vectors."],"metadata":{}},{"cell_type":"code","source":["pca = PCA(k=2, inputCol=\"std_features\", outputCol=\"pca\")\nmodel = pca.fit(german)\ntransformed = model.transform(german)\n\nafter_pca_transformed_Data = transformed\n\nprint type(after_pca_transformed_Data)\n\nafter_pca_transformed_Data.show(4)\n\nprint type(model)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["###We split the data into training (75%) and use the rest (25%) as test set."],"metadata":{}},{"cell_type":"code","source":["train_f, test_f = after_pca_transformed_Data.randomSplit([0.75,0.25],seed=123)\n\nprint type(test_f)\n\ntrain_f.collect()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["from numpy import array\nimport numpy as np\nfeatures = train_f.map(lambda row:array(row.pca))\n\n\nfeatures.take(2)\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["###Build Model :A clustering model derived from the Gaussian Mixture Model method.\ngaussians is a array of MultivariateGaussian where gaussians[i] represents the Multivariate Gaussian (Normal) Distribution for Gaussian i.\n\nk - Number of gaussians in mixture."],"metadata":{}},{"cell_type":"code","source":["# gmm is a model\ngmm = GaussianMixture.train(features,2)\n\nprint gmm"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# output parameters of model\nfor i in range(2):\n    print (\"weight = \", gmm.weights[i], \"mu = \", gmm.gaussians[i].mu,\n        \"sigma = \", gmm.gaussians[i].sigma.toArray())"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["x_train = np.array(features.map(lambda row:array(row)).collect()).squeeze()\n\nx_train"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["from scipy import linalg\n\ncolor_iter = ['r','g']\n\nsplot = plt.subplot(111)\nfor i in range(2):\n    mean = gmm.gaussians[i].mu\n    covar = gmm.gaussians[i].sigma.toArray()\n    color = color_iter[i]\n    v, w =linalg.eigh(covar)\n    u = w[0]/linalg.norm(w[0])\n    \n    plt.scatter(x_train[:, 0], x_train[:, 1], .8, color=color)\n    angle = np.arctan(u[1]/u[0])\n    angle = 180*angle/np.pi\n    ell = mpl.patches.Ellipse(mean, v[0], v[1], 180+angle, color = color)\n    ell.set_clip_box(plt.box)\n    ell.set_alpha(0.5)\n    splot.add_artist(ell)\n    \nplt.title(\"PySpark dataset with Gaussian Models aligned\")\n\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["###Optimize and fit the model to data"],"metadata":{}},{"cell_type":"code","source":["predict = gmm.predict(test_f.map(lambda row:array(row.pca))).collect()\n\nlabels = test_f.select('label_idx').rdd.map(lambda r: r[0]).collect()\n\nprint predict"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["###Post-processing and model evaluation"],"metadata":{}},{"cell_type":"code","source":["np.corrcoef(predict, labels)\n\n"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["#### Plot discrepancy between predicted and labels"],"metadata":{}},{"cell_type":"code","source":["\n#Remove single-dimensional entries from the shape of an array.\nxs = np.array(test_f.map(lambda row:array(row.pca)).collect()).squeeze()\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\naxes[0].scatter(xs[:, 0], xs[:,1], c=predict)\naxes[0].set_title('Predicted')\n\naxes[1].scatter(xs[:, 0], xs[:,1], c=labels)\naxes[1].set_title('Labels')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["### Apply Supervised MLLIB"],"metadata":{}},{"cell_type":"markdown","source":["###Convert to format expected by regression functions in mllib"],"metadata":{}},{"cell_type":"code","source":["\ntrain_f = train_f.map(lambda x: LabeledPoint(x[2], x[0]))\n\nprint type(train_f)\n\ntrain_f.take(4)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["test_f.show(4)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["### Model on train data using logistic regression for Binary classification data"],"metadata":{}},{"cell_type":"code","source":["model = LogisticRegressionWithLBFGS.train(train_f)\n"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["### Evaluate on test data"],"metadata":{}},{"cell_type":"code","source":["eval_data = test_f.map(lambda x: (x.label_idx, float(model.predict(x.std_features))))\n\n\nerr = eval_data.filter(lambda x: x[0] != x[1]).count() / float(test_f.count())\nprint(\"Error = \" + str(err))\n\nprint(\"Test Count =\")\nprint(test_f.count())\n\n\nsuccess_count_new = eval_data.filter(lambda rec:\n                                            rec[0] == rec[1]).count()\n\n\n\nprint(\"Accuracy data :Successful prediction percentage: \" +\n    str( round( success_count_new / float(test_f.count()), 4 ) ) )\n\n\neval_data.take(4)\n\n"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["### Final Result :\n### Create a confusion metrics to understand True positive rates and False Positive Rates"],"metadata":{}},{"cell_type":"code","source":["from sklearn import metrics\nimport seaborn as sn \n\n\n#fig_heatmap = plt.figure(figsize=(10, 8))\nlabelsAndPreds_Eval_data= eval_data.toDF().toPandas()\ncm = metrics.confusion_matrix( labelsAndPreds_Eval_data._1, labelsAndPreds_Eval_data._2 )\n\nf = plt.figure(figsize=(10, 8))\nplt.title('Confusion matrix of the classifier')\nsn.heatmap(cm, annot=True, fmt='.2f' )\nplt.close()\ndisplay(f)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["###Final Result : Evaluate Anomaly detectors can be evaluated on the same metrics as binary classifiers. Area under the ROC curve provides a good way to measure the discriminatory power of the"],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\n\n\ndef prepare_plot(xticks, yticks, figsize=(10.5, 6), hide_labels=False, grid_color='#999999',\n                 grid_width=1.0):\n    \"\"\"Template for generating the plot layout.\"\"\"\n    plt.close()\n    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n        axis.set_ticks_position('none')\n        axis.set_ticks(ticks)\n        axis.label.set_color('#999999')\n        if hide_labels: axis.set_ticklabels([])\n    plt.grid(color=grid_color, linewidth=grid_width, linestyle='-')\n    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n    return fig, ax"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["### We will now visualize how well the model predicts our target. To do this we generate a plot of the ROC curve. The ROC curve shows us the trade-off between the false positive rate and true positive rate, as we liberalize the threshold required to predict a positive outcome. A random model is represented by the dashed line."],"metadata":{}},{"cell_type":"code","source":["labels_and_scores = test_f.map(lambda x: (x.label_idx, float(model.predict(x.std_features))))\nlabels_and_weights = labels_and_scores.collect()\nlabels_and_weights.sort(key=lambda (k, v): v, reverse=True)\nlabels_by_weight = np.array([k for (k, v) in labels_and_weights])\n\nlength = labels_by_weight.size\ntrue_positives = labels_by_weight.cumsum()\nnum_positive = true_positives[-1]\nfalse_positives = np.arange(1.0, length + 1, 1.) - true_positives\n\ntrue_positive_rate = true_positives / num_positive\nfalse_positive_rate = false_positives / (length - num_positive)\n\nAUC = 0\n# Generate layout and plot data\nfig, ax = prepare_plot(np.arange(0., 1.1, 0.1), np.arange(0., 1.1, 0.1))\nax.set_xlim(-.05, 1.05), ax.set_ylim(-.05, 1.05)\nax.set_ylabel('True Positive Rate') \nax.set_xlabel('False Positive Rate')\nplt.title(\"Accuracy data :Successful prediction percentage: \" +\n    str( round( success_count_new / float(test_f.count()), 4 ) ))\nplt.plot(false_positive_rate, true_positive_rate, color='r', linestyle='-', linewidth=3.)\nplt.plot((0., 1.), (0., 1.), linestyle='--', color='g', linewidth=2.)  # Baseline model\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["print false_positive_rate[0:70]"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision, recall, fscore, support = score(labels,predict)\n\n\nprint('precision: {}'.format(precision))\nprint('recall: {}'.format(recall))\nprint('fscore: {}'.format(fscore))\nprint('support: {}'.format(support))\n\n#print labels,predict"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["###Plot risky and non risky data"],"metadata":{}},{"cell_type":"code","source":["\n\n#Remove single-dimensional entries from the shape of an array.\nnorm_data =german.filter(german.label == 1)\n\nrisky_data =german.filter(german.label == 2)\n\ncommon_data = german.map(lambda l:array(l.std_features))\n\nnorm_Features = norm_data.map(lambda l:array(l.std_features))\nrisky_Features = risky_data.map(lambda l:array(l.std_features))\n\n\n#Remove single-dimensional entries from the shape of an array.\n\nxs = np.array(norm_Features.collect()).squeeze()\nxs_r = np.array(risky_Features.collect()).squeeze()\n\nxs_comman = np.array(common_data.collect()).squeeze()\n\n\n\nfig, axes = plt.subplots(1, 3, figsize=(10, 4))\naxes[0].scatter(xs[0:10], xs[10:20], c='g')\naxes[0].set_title('Normal data')\naxes[1].scatter(xs_r[0:10], xs_r[10:20], c='r')\naxes[1].set_title('Risky Data')\naxes[2].scatter(xs_comman[0:10], xs_comman[10:20])\naxes[2].set_title('Comman Data')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\nx = range(100)\ny = range(100,200)\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.scatter(xs[0:481], xs[481:962], s=10, c='b', marker=\"s\", label='Normal Data')\nax1.scatter(xs_r[0:18], xs_r[18:36], s=10, c='r', marker=\"o\", label='Risky Data')\n#ax1.scatter(xs_comman[0:500], xs_comman[500:1000], s=10, c='g', marker=\"o\", label='Comman Data')\nplt.legend(loc='upper left');\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":54}],"metadata":{"name":"Sample_GC_Analysis","notebookId":4202209118539197},"nbformat":4,"nbformat_minor":0}
